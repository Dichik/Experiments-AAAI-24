{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a9241de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs import config\n",
    "from configs.constants import ModelSetting\n",
    "from utils.analyzers.stability_fairness_analyzer import StabilityFairnessAnalyzer\n",
    "from utils.common_helpers import create_tuned_base_model, save_metrics_to_file\n",
    "from utils.custom_classes.data_loader import ACSEmploymentDataset\n",
    "from utils.custom_classes.generic_pipeline import GenericPipeline\n",
    "from utils.analyzers.bias_analyzer import BiasAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "STATE = config.DATASET_CONFIG['state']\n",
    "YEAR = config.DATASET_CONFIG['year']\n",
    "DATASET_NAME = f\"Folktables_{STATE}_{YEAR}\"\n",
    "EXPERIMENT_NAME = 'Hypothesis_Space'\n",
    "\n",
    "SEX_priv = RACE_priv = str(1)\n",
    "N_ESTIMATORS = 100\n",
    "PROTECTED_GROUPS = ['SEX','RAC1P']\n",
    "PRIV_VALUES = [SEX_priv, RACE_priv]\n",
    "TUNED_PARAMS_FILE_PATH = os.path.join('..', '..', 'results', 'models_tuning', 'tuning_results_Folktables_GA_2018_20221215__105658.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models tuned hyper-parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0        Dataset_Name                   Model_Name  F1_Score  \\\n0           0  Folktables_GA_2018           LogisticRegression    0.8117   \n1           1  Folktables_GA_2018       DecisionTreeClassifier    0.8228   \n2           2  Folktables_GA_2018       RandomForestClassifier    0.8292   \n3           3  Folktables_GA_2018                XGBClassifier    0.8313   \n4           4  Folktables_GA_2018         KNeighborsClassifier    0.8063   \n5           5  Folktables_GA_2018         MLPClassifier_1L_100       NaN   \n6           6  Folktables_GA_2018  MLPClassifier_3L_100_50_100       NaN   \n7           7  Folktables_GA_2018                          SVC    0.8247   \n\n   Accuracy_Score                                  Model_Best_Params  \n0          0.8122  {'max_iter': 50, 'penalty': 'l2', 'solver': 'l...  \n1          0.8230  {'criterion': 'entropy', 'max_depth': 10, 'max...  \n2          0.8295  {'max_depth': 10, 'max_features': 0.6, 'min_sa...  \n3          0.8318  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...  \n4          0.8068  {'metric': 'manhattan', 'n_neighbors': 15, 'we...  \n5             NaN                                                 {}  \n6             NaN                                                 {}  \n7          0.8250       {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Dataset_Name</th>\n      <th>Model_Name</th>\n      <th>F1_Score</th>\n      <th>Accuracy_Score</th>\n      <th>Model_Best_Params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Folktables_GA_2018</td>\n      <td>LogisticRegression</td>\n      <td>0.8117</td>\n      <td>0.8122</td>\n      <td>{'max_iter': 50, 'penalty': 'l2', 'solver': 'l...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Folktables_GA_2018</td>\n      <td>DecisionTreeClassifier</td>\n      <td>0.8228</td>\n      <td>0.8230</td>\n      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Folktables_GA_2018</td>\n      <td>RandomForestClassifier</td>\n      <td>0.8292</td>\n      <td>0.8295</td>\n      <td>{'max_depth': 10, 'max_features': 0.6, 'min_sa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Folktables_GA_2018</td>\n      <td>XGBClassifier</td>\n      <td>0.8313</td>\n      <td>0.8318</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Folktables_GA_2018</td>\n      <td>KNeighborsClassifier</td>\n      <td>0.8063</td>\n      <td>0.8068</td>\n      <td>{'metric': 'manhattan', 'n_neighbors': 15, 'we...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Folktables_GA_2018</td>\n      <td>MLPClassifier_1L_100</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Folktables_GA_2018</td>\n      <td>MLPClassifier_3L_100_50_100</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Folktables_GA_2018</td>\n      <td>SVC</td>\n      <td>0.8247</td>\n      <td>0.8250</td>\n      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_tuned_params_df = pd.read_csv(TUNED_PARAMS_FILE_PATH)\n",
    "models_tuned_params_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fafa0c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  MAR MIL ESP MIG DREM NATIVITY DIS DEAR DEYE SEX RAC1P RELP CIT ANC SCHL  \\\n0   5   4   0   3    2        1   2    2    2   1     2   16   1   1   13   \n1   3   4   0   1    2        1   1    2    1   2     1   16   1   4   16   \n2   5   4   0   1    1        1   1    2    2   2     2   17   1   4   20   \n3   1   4   0   1    2        1   2    2    2   1     2   16   1   1   17   \n4   5   4   0   1    2        1   2    2    2   2     1   16   1   1   19   \n\n   AGEP  \n0    51  \n1    56  \n2    23  \n3    43  \n4    20  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAR</th>\n      <th>MIL</th>\n      <th>ESP</th>\n      <th>MIG</th>\n      <th>DREM</th>\n      <th>NATIVITY</th>\n      <th>DIS</th>\n      <th>DEAR</th>\n      <th>DEYE</th>\n      <th>SEX</th>\n      <th>RAC1P</th>\n      <th>RELP</th>\n      <th>CIT</th>\n      <th>ANC</th>\n      <th>SCHL</th>\n      <th>AGEP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>16</td>\n      <td>1</td>\n      <td>4</td>\n      <td>16</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>17</td>\n      <td>1</td>\n      <td>4</td>\n      <td>20</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>17</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>19</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ACSEmploymentDataset(state=[STATE], year=YEAR, root_dir=os.path.join('..', '..', 'data'), with_nulls=False)\n",
    "dataset.X_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def create_base_pipeline(dataset, protected_groups, priv_values, model_seed):\n",
    "    base_pipeline = GenericPipeline(dataset, protected_groups, priv_values)\n",
    "    _ = base_pipeline.create_preprocessed_train_test_split(dataset, config.TEST_SET_FRACTION, seed=model_seed)\n",
    "\n",
    "    print('\\nProtected groups splits:')\n",
    "    for g in base_pipeline.test_groups.keys():\n",
    "        print(g, base_pipeline.test_groups[g].shape)\n",
    "\n",
    "    return base_pipeline\n",
    "\n",
    "\n",
    "def get_model_metrics(base_model, n_estimators, dataset, protected_groups, priv_values, model_seed,\n",
    "                      dataset_name, base_model_name, exp_num=1):\n",
    "    base_pipeline = create_base_pipeline(dataset, protected_groups, priv_values, model_seed)\n",
    "\n",
    "    stability_fairness_analyzer = StabilityFairnessAnalyzer(ModelSetting.BATCH, n_estimators, base_model, base_model_name,\n",
    "                                                            base_pipeline.X_train_val, base_pipeline.y_train_val,\n",
    "                                                            base_pipeline.X_test, base_pipeline.y_test,\n",
    "                                                            base_pipeline.protected_groups, base_pipeline.priv_values, base_pipeline.test_groups,\n",
    "                                                            base_pipeline.target, dataset_name)\n",
    "\n",
    "    save_results = False\n",
    "    y_preds, variance_metrics_df = stability_fairness_analyzer.compute_metrics(save_results=save_results,\n",
    "                                                                               result_filename=None,\n",
    "                                                                               save_dir_path=None,\n",
    "                                                                               make_plots=True)\n",
    "\n",
    "    bias_analyzer = BiasAnalyzer(base_pipeline.X_test, base_pipeline.y_test,\n",
    "                                 base_pipeline.protected_groups, base_pipeline.priv_values,\n",
    "                                 base_pipeline.test_groups)\n",
    "    dtc_res = bias_analyzer.compute_subgroups_metrics(y_preds,\n",
    "                                                      save_results=False,\n",
    "                                                      result_filename=None,\n",
    "                                                      save_dir_path=None)\n",
    "    bias_metrics_df = pd.DataFrame(dtc_res)\n",
    "\n",
    "    metrics_df = pd.concat([variance_metrics_df, bias_metrics_df])\n",
    "    result_filename = f'{EXPERIMENT_NAME}_Metrics_{dataset_name}_Experiment_{exp_num}_{base_model_name}'\n",
    "    save_dir_path = os.path.join('..', '..', 'results', 'hypothesis_space')\n",
    "    save_metrics_to_file(metrics_df, result_filename, save_dir_path)\n",
    "\n",
    "    return metrics_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def run_experiment(exp_num, model_seed):\n",
    "    for model_idx in tqdm(range(len(config.MODELS_CONFIG))):\n",
    "        print('#' * 30, f' [Experiment {exp_num}] Analyze {config.MODELS_CONFIG[model_idx][\"model_name\"]} ', '#' * 30)\n",
    "        model_seed += 1\n",
    "        base_model = create_tuned_base_model(config.MODELS_CONFIG[model_idx]['model'],\n",
    "                                             config.MODELS_CONFIG[model_idx]['model_name'],\n",
    "                                             models_tuned_params_df)\n",
    "        results_df = get_model_metrics(base_model, N_ESTIMATORS, dataset, PROTECTED_GROUPS, PRIV_VALUES,\n",
    "                                       model_seed=model_seed,\n",
    "                                       dataset_name=DATASET_NAME,\n",
    "                                       base_model_name=config.MODELS_CONFIG[model_idx]['model_name'],\n",
    "                                       exp_num=exp_num)\n",
    "        print(f'\\n[Experiment {exp_num}] Metrics confusion matrix:')\n",
    "        display(results_df)\n",
    "\n",
    "        print('\\n\\n\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################  [Experiment 1] Analyze DecisionTreeClassifier  ##############################\n",
      "Baseline X_train shape:  (80684, 16)\n",
      "Baseline X_test shape:  (20171, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 04:24:50 abstract_stability_analyzer.py INFO    : Start testing of classifier 1 / 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Protected groups splits:\n",
      "SEX_RAC1P_priv (6609, 16)\n",
      "SEX_RAC1P_dis (3662, 16)\n",
      "SEX_priv (9901, 16)\n",
      "SEX_dis (10270, 16)\n",
      "RAC1P_priv (13217, 16)\n",
      "RAC1P_dis (6954, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 04:24:51 abstract_stability_analyzer.py INFO    : Classifier 1 / 100 was tested\n",
      "2022-12-16 04:24:51 abstract_stability_analyzer.py INFO    : Start testing of classifier 2 / 100\n",
      "2022-12-16 04:24:51 abstract_stability_analyzer.py INFO    : Classifier 2 / 100 was tested\n",
      "2022-12-16 04:24:51 abstract_stability_analyzer.py INFO    : Start testing of classifier 3 / 100\n",
      "2022-12-16 04:24:52 abstract_stability_analyzer.py INFO    : Classifier 3 / 100 was tested\n",
      "2022-12-16 04:24:52 abstract_stability_analyzer.py INFO    : Start testing of classifier 4 / 100\n",
      "2022-12-16 04:24:52 abstract_stability_analyzer.py INFO    : Classifier 4 / 100 was tested\n",
      "2022-12-16 04:24:52 abstract_stability_analyzer.py INFO    : Start testing of classifier 5 / 100\n",
      "2022-12-16 04:24:53 abstract_stability_analyzer.py INFO    : Classifier 5 / 100 was tested\n",
      "2022-12-16 04:24:53 abstract_stability_analyzer.py INFO    : Start testing of classifier 6 / 100\n",
      "2022-12-16 04:24:53 abstract_stability_analyzer.py INFO    : Classifier 6 / 100 was tested\n",
      "2022-12-16 04:24:53 abstract_stability_analyzer.py INFO    : Start testing of classifier 7 / 100\n",
      "2022-12-16 04:24:53 abstract_stability_analyzer.py INFO    : Classifier 7 / 100 was tested\n",
      "2022-12-16 04:24:53 abstract_stability_analyzer.py INFO    : Start testing of classifier 8 / 100\n",
      "2022-12-16 04:24:54 abstract_stability_analyzer.py INFO    : Classifier 8 / 100 was tested\n",
      "2022-12-16 04:24:54 abstract_stability_analyzer.py INFO    : Start testing of classifier 9 / 100\n",
      "2022-12-16 04:24:54 abstract_stability_analyzer.py INFO    : Classifier 9 / 100 was tested\n",
      "2022-12-16 04:24:54 abstract_stability_analyzer.py INFO    : Start testing of classifier 10 / 100\n",
      "2022-12-16 04:24:55 abstract_stability_analyzer.py INFO    : Classifier 10 / 100 was tested\n",
      "2022-12-16 04:24:55 abstract_stability_analyzer.py INFO    : Start testing of classifier 11 / 100\n",
      "2022-12-16 04:24:55 abstract_stability_analyzer.py INFO    : Classifier 11 / 100 was tested\n",
      "2022-12-16 04:24:55 abstract_stability_analyzer.py INFO    : Start testing of classifier 12 / 100\n",
      "2022-12-16 04:24:56 abstract_stability_analyzer.py INFO    : Classifier 12 / 100 was tested\n",
      "2022-12-16 04:24:56 abstract_stability_analyzer.py INFO    : Start testing of classifier 13 / 100\n",
      "2022-12-16 04:24:56 abstract_stability_analyzer.py INFO    : Classifier 13 / 100 was tested\n",
      "2022-12-16 04:24:56 abstract_stability_analyzer.py INFO    : Start testing of classifier 14 / 100\n",
      "2022-12-16 04:24:56 abstract_stability_analyzer.py INFO    : Classifier 14 / 100 was tested\n",
      "2022-12-16 04:24:56 abstract_stability_analyzer.py INFO    : Start testing of classifier 15 / 100\n",
      "2022-12-16 04:24:57 abstract_stability_analyzer.py INFO    : Classifier 15 / 100 was tested\n",
      "2022-12-16 04:24:57 abstract_stability_analyzer.py INFO    : Start testing of classifier 16 / 100\n",
      "2022-12-16 04:24:57 abstract_stability_analyzer.py INFO    : Classifier 16 / 100 was tested\n",
      "2022-12-16 04:24:57 abstract_stability_analyzer.py INFO    : Start testing of classifier 17 / 100\n",
      "2022-12-16 04:24:58 abstract_stability_analyzer.py INFO    : Classifier 17 / 100 was tested\n",
      "2022-12-16 04:24:58 abstract_stability_analyzer.py INFO    : Start testing of classifier 18 / 100\n",
      "2022-12-16 04:24:58 abstract_stability_analyzer.py INFO    : Classifier 18 / 100 was tested\n",
      "2022-12-16 04:24:58 abstract_stability_analyzer.py INFO    : Start testing of classifier 19 / 100\n",
      "2022-12-16 04:24:59 abstract_stability_analyzer.py INFO    : Classifier 19 / 100 was tested\n",
      "2022-12-16 04:24:59 abstract_stability_analyzer.py INFO    : Start testing of classifier 20 / 100\n",
      "2022-12-16 04:24:59 abstract_stability_analyzer.py INFO    : Classifier 20 / 100 was tested\n",
      "2022-12-16 04:24:59 abstract_stability_analyzer.py INFO    : Start testing of classifier 21 / 100\n",
      "2022-12-16 04:24:59 abstract_stability_analyzer.py INFO    : Classifier 21 / 100 was tested\n",
      "2022-12-16 04:24:59 abstract_stability_analyzer.py INFO    : Start testing of classifier 22 / 100\n",
      "2022-12-16 04:25:00 abstract_stability_analyzer.py INFO    : Classifier 22 / 100 was tested\n",
      "2022-12-16 04:25:00 abstract_stability_analyzer.py INFO    : Start testing of classifier 23 / 100\n",
      "2022-12-16 04:25:00 abstract_stability_analyzer.py INFO    : Classifier 23 / 100 was tested\n",
      "2022-12-16 04:25:00 abstract_stability_analyzer.py INFO    : Start testing of classifier 24 / 100\n",
      "2022-12-16 04:25:01 abstract_stability_analyzer.py INFO    : Classifier 24 / 100 was tested\n",
      "2022-12-16 04:25:01 abstract_stability_analyzer.py INFO    : Start testing of classifier 25 / 100\n",
      "2022-12-16 04:25:01 abstract_stability_analyzer.py INFO    : Classifier 25 / 100 was tested\n",
      "2022-12-16 04:25:01 abstract_stability_analyzer.py INFO    : Start testing of classifier 26 / 100\n",
      "2022-12-16 04:25:01 abstract_stability_analyzer.py INFO    : Classifier 26 / 100 was tested\n",
      "2022-12-16 04:25:01 abstract_stability_analyzer.py INFO    : Start testing of classifier 27 / 100\n",
      "2022-12-16 04:25:02 abstract_stability_analyzer.py INFO    : Classifier 27 / 100 was tested\n",
      "2022-12-16 04:25:02 abstract_stability_analyzer.py INFO    : Start testing of classifier 28 / 100\n",
      "2022-12-16 04:25:02 abstract_stability_analyzer.py INFO    : Classifier 28 / 100 was tested\n",
      "2022-12-16 04:25:02 abstract_stability_analyzer.py INFO    : Start testing of classifier 29 / 100\n",
      "2022-12-16 04:25:03 abstract_stability_analyzer.py INFO    : Classifier 29 / 100 was tested\n",
      "2022-12-16 04:25:03 abstract_stability_analyzer.py INFO    : Start testing of classifier 30 / 100\n",
      "2022-12-16 04:25:03 abstract_stability_analyzer.py INFO    : Classifier 30 / 100 was tested\n",
      "2022-12-16 04:25:03 abstract_stability_analyzer.py INFO    : Start testing of classifier 31 / 100\n",
      "2022-12-16 04:25:04 abstract_stability_analyzer.py INFO    : Classifier 31 / 100 was tested\n",
      "2022-12-16 04:25:04 abstract_stability_analyzer.py INFO    : Start testing of classifier 32 / 100\n",
      "2022-12-16 04:25:04 abstract_stability_analyzer.py INFO    : Classifier 32 / 100 was tested\n",
      "2022-12-16 04:25:04 abstract_stability_analyzer.py INFO    : Start testing of classifier 33 / 100\n"
     ]
    }
   ],
   "source": [
    "# TOD: add dataset as a parameter\n",
    "run_experiment(exp_num=1, model_seed=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run_experiment(exp_num=2, model_seed=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}