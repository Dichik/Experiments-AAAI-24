{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9241de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs import config\n",
    "from configs.constants import ModelSetting\n",
    "from utils.analyzers.stability_fairness_analyzer import StabilityFairnessAnalyzer\n",
    "from utils.common_helpers import create_tuned_base_model, save_metrics_to_file\n",
    "from utils.custom_classes.data_loader import ACSEmploymentDataset\n",
    "from utils.custom_classes.generic_pipeline import GenericPipeline\n",
    "from utils.analyzers.bias_analyzer import BiasAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "STATE = config.DATASET_CONFIG['state']\n",
    "YEAR = config.DATASET_CONFIG['year']\n",
    "DATASET_NAME = f\"Folktables_{STATE}_{YEAR}\"\n",
    "EXPERIMENT_NAME = 'Hypothesis_Space'\n",
    "\n",
    "SEX_priv = RACE_priv = str(1)\n",
    "# N_ESTIMATORS = 200\n",
    "N_ESTIMATORS = 10\n",
    "PROTECTED_GROUPS = ['SEX','RAC1P']\n",
    "PRIV_VALUES = [SEX_priv, RACE_priv]\n",
    "TUNED_PARAMS_FILE_PATH = os.path.join('..', '..', 'results', 'models_tuning', 'tuning_results_Folktables_GA_2018_20221215__105658.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models tuned hyper-parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_tuned_params_df = pd.read_csv(TUNED_PARAMS_FILE_PATH)\n",
    "models_tuned_params_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = ACSEmploymentDataset(state=[STATE], year=YEAR, root_dir=os.path.join('..', '..', 'data'), with_nulls=False)\n",
    "dataset.X_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_base_pipeline(dataset, protected_groups, priv_values, model_seed):\n",
    "    base_pipeline = GenericPipeline(dataset, protected_groups, priv_values)\n",
    "    _ = base_pipeline.create_preprocessed_train_test_split(dataset, config.TEST_SET_FRACTION, seed=model_seed)\n",
    "\n",
    "    print('\\nProtected groups splits:')\n",
    "    for g in base_pipeline.test_groups.keys():\n",
    "        print(g, base_pipeline.test_groups[g].shape)\n",
    "\n",
    "    return base_pipeline\n",
    "\n",
    "\n",
    "def get_model_metrics(base_model, n_estimators, dataset, protected_groups, priv_values, model_seed,\n",
    "                      dataset_name, base_model_name, exp_num=1):\n",
    "    base_pipeline = create_base_pipeline(dataset, protected_groups, priv_values, model_seed)\n",
    "\n",
    "    stability_fairness_analyzer = StabilityFairnessAnalyzer(ModelSetting.BATCH, n_estimators, base_model, base_model_name,\n",
    "                                                            base_pipeline.X_train_val, base_pipeline.y_train_val,\n",
    "                                                            base_pipeline.X_test, base_pipeline.y_test,\n",
    "                                                            base_pipeline.protected_groups, base_pipeline.priv_values, base_pipeline.test_groups,\n",
    "                                                            base_pipeline.target, dataset_name)\n",
    "\n",
    "    save_results = False\n",
    "    y_preds, variance_metrics_df = stability_fairness_analyzer.compute_metrics(save_results=save_results,\n",
    "                                                                               result_filename=None,\n",
    "                                                                               save_dir_path=None,\n",
    "                                                                               make_plots=False)\n",
    "\n",
    "    bias_analyzer = BiasAnalyzer(base_pipeline.X_test, base_pipeline.y_test,\n",
    "                                 base_pipeline.protected_groups, base_pipeline.priv_values,\n",
    "                                 base_pipeline.test_groups)\n",
    "    dtc_res = bias_analyzer.compute_subgroups_metrics(y_preds,\n",
    "                                                      save_results=False,\n",
    "                                                      result_filename=None,\n",
    "                                                      save_dir_path=None)\n",
    "    bias_metrics_df = pd.DataFrame(dtc_res)\n",
    "\n",
    "    metrics_df = pd.concat([variance_metrics_df, bias_metrics_df])\n",
    "    result_filename = f'{EXPERIMENT_NAME}_Metrics_{dataset_name}_Experiment_{exp_num}_{base_model_name}'\n",
    "    save_dir_path = os.path.join('..', '..', 'results', 'hypothesis_space')\n",
    "    save_metrics_to_file(metrics_df, result_filename, save_dir_path)\n",
    "\n",
    "    return metrics_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_experiment(exp_num, model_seed):\n",
    "    for model_idx in tqdm(range(len(config.MODELS_CONFIG))):\n",
    "        print('#' * 30, f' [Experiment {exp_num}] Analyze {config.MODELS_CONFIG[model_idx][\"model_name\"]} ', '#' * 30)\n",
    "        model_seed += 1\n",
    "        try:\n",
    "            base_model = create_tuned_base_model(config.MODELS_CONFIG[model_idx]['model'],\n",
    "                                                 config.MODELS_CONFIG[model_idx]['model_name'],\n",
    "                                                 models_tuned_params_df)\n",
    "            results_df = get_model_metrics(base_model, N_ESTIMATORS, dataset, PROTECTED_GROUPS, PRIV_VALUES,\n",
    "                                           model_seed=model_seed,\n",
    "                                           dataset_name=DATASET_NAME,\n",
    "                                           base_model_name=config.MODELS_CONFIG[model_idx]['model_name'],\n",
    "                                           exp_num=exp_num)\n",
    "            print(f'\\n[Experiment {exp_num}] Metrics confusion matrix:')\n",
    "            display(results_df)\n",
    "        except Exception as err:\n",
    "            print(f'ERROR with {config.MODELS_CONFIG[model_idx][\"model_name\"]}: ', err)\n",
    "\n",
    "        print('\\n\\n\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################  [Experiment 1] Analyze XGBClassifier  ##############################\n",
      "Baseline X_train shape:  (80684, 16)\n",
      "Baseline X_test shape:  (20171, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:23:59 abstract_stability_analyzer.py INFO    : Start testing of classifier 1 / 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Protected groups splits:\n",
      "SEX_RAC1P_priv (6609, 16)\n",
      "SEX_RAC1P_dis (3662, 16)\n",
      "SEX_priv (9901, 16)\n",
      "SEX_dis (10270, 16)\n",
      "RAC1P_priv (13217, 16)\n",
      "RAC1P_dis (6954, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:24:19 abstract_stability_analyzer.py INFO    : Classifier 1 / 50 was tested\n",
      "2022-12-16 10:24:19 abstract_stability_analyzer.py INFO    : Start testing of classifier 2 / 50\n",
      "2022-12-16 10:24:33 abstract_stability_analyzer.py INFO    : Classifier 2 / 50 was tested\n",
      "2022-12-16 10:24:33 abstract_stability_analyzer.py INFO    : Start testing of classifier 3 / 50\n",
      "2022-12-16 10:24:49 abstract_stability_analyzer.py INFO    : Classifier 3 / 50 was tested\n",
      "2022-12-16 10:24:49 abstract_stability_analyzer.py INFO    : Start testing of classifier 4 / 50\n",
      "2022-12-16 10:25:13 abstract_stability_analyzer.py INFO    : Classifier 4 / 50 was tested\n",
      "2022-12-16 10:25:13 abstract_stability_analyzer.py INFO    : Start testing of classifier 5 / 50\n",
      "2022-12-16 10:25:32 abstract_stability_analyzer.py INFO    : Classifier 5 / 50 was tested\n",
      "2022-12-16 10:25:32 abstract_stability_analyzer.py INFO    : Start testing of classifier 6 / 50\n",
      "2022-12-16 10:25:46 abstract_stability_analyzer.py INFO    : Classifier 6 / 50 was tested\n",
      "2022-12-16 10:25:46 abstract_stability_analyzer.py INFO    : Start testing of classifier 7 / 50\n",
      "2022-12-16 10:26:00 abstract_stability_analyzer.py INFO    : Classifier 7 / 50 was tested\n",
      "2022-12-16 10:26:00 abstract_stability_analyzer.py INFO    : Start testing of classifier 8 / 50\n",
      "2022-12-16 10:26:14 abstract_stability_analyzer.py INFO    : Classifier 8 / 50 was tested\n",
      "2022-12-16 10:26:14 abstract_stability_analyzer.py INFO    : Start testing of classifier 9 / 50\n",
      "2022-12-16 10:26:27 abstract_stability_analyzer.py INFO    : Classifier 9 / 50 was tested\n",
      "2022-12-16 10:26:27 abstract_stability_analyzer.py INFO    : Start testing of classifier 10 / 50\n",
      "2022-12-16 10:26:40 abstract_stability_analyzer.py INFO    : Classifier 10 / 50 was tested\n",
      "2022-12-16 10:26:40 abstract_stability_analyzer.py INFO    : Start testing of classifier 11 / 50\n",
      "2022-12-16 10:26:57 abstract_stability_analyzer.py INFO    : Classifier 11 / 50 was tested\n",
      "2022-12-16 10:26:57 abstract_stability_analyzer.py INFO    : Start testing of classifier 12 / 50\n",
      "2022-12-16 10:27:10 abstract_stability_analyzer.py INFO    : Classifier 12 / 50 was tested\n",
      "2022-12-16 10:27:10 abstract_stability_analyzer.py INFO    : Start testing of classifier 13 / 50\n",
      "2022-12-16 10:27:23 abstract_stability_analyzer.py INFO    : Classifier 13 / 50 was tested\n",
      "2022-12-16 10:27:23 abstract_stability_analyzer.py INFO    : Start testing of classifier 14 / 50\n",
      "2022-12-16 10:27:37 abstract_stability_analyzer.py INFO    : Classifier 14 / 50 was tested\n",
      "2022-12-16 10:27:37 abstract_stability_analyzer.py INFO    : Start testing of classifier 15 / 50\n",
      "2022-12-16 10:27:51 abstract_stability_analyzer.py INFO    : Classifier 15 / 50 was tested\n",
      "2022-12-16 10:27:51 abstract_stability_analyzer.py INFO    : Start testing of classifier 16 / 50\n",
      "2022-12-16 10:28:04 abstract_stability_analyzer.py INFO    : Classifier 16 / 50 was tested\n",
      "2022-12-16 10:28:04 abstract_stability_analyzer.py INFO    : Start testing of classifier 17 / 50\n",
      "2022-12-16 10:28:17 abstract_stability_analyzer.py INFO    : Classifier 17 / 50 was tested\n",
      "2022-12-16 10:28:17 abstract_stability_analyzer.py INFO    : Start testing of classifier 18 / 50\n",
      "2022-12-16 10:28:30 abstract_stability_analyzer.py INFO    : Classifier 18 / 50 was tested\n",
      "2022-12-16 10:28:30 abstract_stability_analyzer.py INFO    : Start testing of classifier 19 / 50\n",
      "2022-12-16 10:28:44 abstract_stability_analyzer.py INFO    : Classifier 19 / 50 was tested\n",
      "2022-12-16 10:28:44 abstract_stability_analyzer.py INFO    : Start testing of classifier 20 / 50\n",
      "2022-12-16 10:28:58 abstract_stability_analyzer.py INFO    : Classifier 20 / 50 was tested\n",
      "2022-12-16 10:28:58 abstract_stability_analyzer.py INFO    : Start testing of classifier 21 / 50\n",
      "2022-12-16 10:29:12 abstract_stability_analyzer.py INFO    : Classifier 21 / 50 was tested\n",
      "2022-12-16 10:29:12 abstract_stability_analyzer.py INFO    : Start testing of classifier 22 / 50\n",
      "2022-12-16 10:29:26 abstract_stability_analyzer.py INFO    : Classifier 22 / 50 was tested\n",
      "2022-12-16 10:29:26 abstract_stability_analyzer.py INFO    : Start testing of classifier 23 / 50\n",
      "2022-12-16 10:29:39 abstract_stability_analyzer.py INFO    : Classifier 23 / 50 was tested\n",
      "2022-12-16 10:29:39 abstract_stability_analyzer.py INFO    : Start testing of classifier 24 / 50\n",
      "2022-12-16 10:29:53 abstract_stability_analyzer.py INFO    : Classifier 24 / 50 was tested\n",
      "2022-12-16 10:29:53 abstract_stability_analyzer.py INFO    : Start testing of classifier 25 / 50\n",
      "2022-12-16 10:30:07 abstract_stability_analyzer.py INFO    : Classifier 25 / 50 was tested\n",
      "2022-12-16 10:30:07 abstract_stability_analyzer.py INFO    : Start testing of classifier 26 / 50\n",
      "2022-12-16 10:30:20 abstract_stability_analyzer.py INFO    : Classifier 26 / 50 was tested\n",
      "2022-12-16 10:30:20 abstract_stability_analyzer.py INFO    : Start testing of classifier 27 / 50\n",
      "2022-12-16 10:30:35 abstract_stability_analyzer.py INFO    : Classifier 27 / 50 was tested\n",
      "2022-12-16 10:30:35 abstract_stability_analyzer.py INFO    : Start testing of classifier 28 / 50\n",
      "2022-12-16 10:30:48 abstract_stability_analyzer.py INFO    : Classifier 28 / 50 was tested\n",
      "2022-12-16 10:30:48 abstract_stability_analyzer.py INFO    : Start testing of classifier 29 / 50\n",
      "2022-12-16 10:31:02 abstract_stability_analyzer.py INFO    : Classifier 29 / 50 was tested\n",
      "2022-12-16 10:31:02 abstract_stability_analyzer.py INFO    : Start testing of classifier 30 / 50\n",
      "2022-12-16 10:31:15 abstract_stability_analyzer.py INFO    : Classifier 30 / 50 was tested\n",
      "2022-12-16 10:31:15 abstract_stability_analyzer.py INFO    : Start testing of classifier 31 / 50\n",
      "2022-12-16 10:31:30 abstract_stability_analyzer.py INFO    : Classifier 31 / 50 was tested\n",
      "2022-12-16 10:31:30 abstract_stability_analyzer.py INFO    : Start testing of classifier 32 / 50\n",
      "2022-12-16 10:31:43 abstract_stability_analyzer.py INFO    : Classifier 32 / 50 was tested\n",
      "2022-12-16 10:31:43 abstract_stability_analyzer.py INFO    : Start testing of classifier 33 / 50\n",
      "2022-12-16 10:31:56 abstract_stability_analyzer.py INFO    : Classifier 33 / 50 was tested\n",
      "2022-12-16 10:31:56 abstract_stability_analyzer.py INFO    : Start testing of classifier 34 / 50\n",
      "2022-12-16 10:32:09 abstract_stability_analyzer.py INFO    : Classifier 34 / 50 was tested\n",
      "2022-12-16 10:32:09 abstract_stability_analyzer.py INFO    : Start testing of classifier 35 / 50\n",
      "2022-12-16 10:32:24 abstract_stability_analyzer.py INFO    : Classifier 35 / 50 was tested\n",
      "2022-12-16 10:32:24 abstract_stability_analyzer.py INFO    : Start testing of classifier 36 / 50\n",
      "2022-12-16 10:32:37 abstract_stability_analyzer.py INFO    : Classifier 36 / 50 was tested\n",
      "2022-12-16 10:32:37 abstract_stability_analyzer.py INFO    : Start testing of classifier 37 / 50\n",
      "2022-12-16 10:32:50 abstract_stability_analyzer.py INFO    : Classifier 37 / 50 was tested\n",
      "2022-12-16 10:32:50 abstract_stability_analyzer.py INFO    : Start testing of classifier 38 / 50\n",
      "2022-12-16 10:33:07 abstract_stability_analyzer.py INFO    : Classifier 38 / 50 was tested\n",
      "2022-12-16 10:33:07 abstract_stability_analyzer.py INFO    : Start testing of classifier 39 / 50\n",
      "2022-12-16 10:33:20 abstract_stability_analyzer.py INFO    : Classifier 39 / 50 was tested\n",
      "2022-12-16 10:33:20 abstract_stability_analyzer.py INFO    : Start testing of classifier 40 / 50\n",
      "2022-12-16 10:33:34 abstract_stability_analyzer.py INFO    : Classifier 40 / 50 was tested\n",
      "2022-12-16 10:33:34 abstract_stability_analyzer.py INFO    : Start testing of classifier 41 / 50\n",
      "2022-12-16 10:33:48 abstract_stability_analyzer.py INFO    : Classifier 41 / 50 was tested\n",
      "2022-12-16 10:33:48 abstract_stability_analyzer.py INFO    : Start testing of classifier 42 / 50\n",
      "2022-12-16 10:34:02 abstract_stability_analyzer.py INFO    : Classifier 42 / 50 was tested\n",
      "2022-12-16 10:34:02 abstract_stability_analyzer.py INFO    : Start testing of classifier 43 / 50\n",
      "2022-12-16 10:34:15 abstract_stability_analyzer.py INFO    : Classifier 43 / 50 was tested\n",
      "2022-12-16 10:34:15 abstract_stability_analyzer.py INFO    : Start testing of classifier 44 / 50\n",
      "2022-12-16 10:34:28 abstract_stability_analyzer.py INFO    : Classifier 44 / 50 was tested\n",
      "2022-12-16 10:34:28 abstract_stability_analyzer.py INFO    : Start testing of classifier 45 / 50\n",
      "2022-12-16 10:34:41 abstract_stability_analyzer.py INFO    : Classifier 45 / 50 was tested\n",
      "2022-12-16 10:34:41 abstract_stability_analyzer.py INFO    : Start testing of classifier 46 / 50\n",
      "2022-12-16 10:34:55 abstract_stability_analyzer.py INFO    : Classifier 46 / 50 was tested\n",
      "2022-12-16 10:34:55 abstract_stability_analyzer.py INFO    : Start testing of classifier 47 / 50\n",
      "2022-12-16 10:35:11 abstract_stability_analyzer.py INFO    : Classifier 47 / 50 was tested\n",
      "2022-12-16 10:35:11 abstract_stability_analyzer.py INFO    : Start testing of classifier 48 / 50\n",
      "2022-12-16 10:35:24 abstract_stability_analyzer.py INFO    : Classifier 48 / 50 was tested\n",
      "2022-12-16 10:35:24 abstract_stability_analyzer.py INFO    : Start testing of classifier 49 / 50\n",
      "2022-12-16 10:35:38 abstract_stability_analyzer.py INFO    : Classifier 49 / 50 was tested\n",
      "2022-12-16 10:35:38 abstract_stability_analyzer.py INFO    : Start testing of classifier 50 / 50\n",
      "2022-12-16 10:35:52 abstract_stability_analyzer.py INFO    : Classifier 50 / 50 was tested\n",
      "2022-12-16 10:36:13 abstract_stability_analyzer.py INFO    : Successfully computed predict proba metrics\n",
      "2022-12-16 10:36:17 abstract_stability_analyzer.py INFO    : Successfully computed predict labels metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##############################  Stability metrics  ##############################\n",
      "General Ensemble Accuracy: 0.8272\n",
      "Mean: 0.5537999868392944\n",
      "Std: 0.026100000366568565\n",
      "IQR: 0.033\n",
      "Entropy: 0.0\n",
      "Jitter: 0.0291\n",
      "Per sample accuracy: 0.8257\n",
      "Label stability: 0.9595\n",
      "\n",
      "\n",
      "\n",
      "[Experiment 1] Metrics confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            overall  SEX_RAC1P_priv  SEX_RAC1P_dis  SEX_priv  \\\nGeneral_Ensemble_Accuracy  0.827200        0.856900       0.806900  0.857500   \nMean                       0.553800        0.491800       0.580500  0.521100   \nStd                        0.026100        0.023500       0.031000  0.024200   \nIQR                        0.033000        0.029600       0.039500  0.030500   \nEntropy                    0.000000        0.000000       0.066300  0.000000   \nJitter                     0.029100        0.020000       0.042800  0.022500   \nPer_Sample_Accuracy        0.825700        0.855500       0.803500  0.856200   \nLabel_Stability            0.959500        0.972700       0.940800  0.969100   \nTPR                        0.858728        0.889514       0.838083  0.886425   \nTNR                        0.801792        0.822765       0.784230  0.830469   \nPPV                        0.777688        0.839765       0.739006  0.830004   \nFNR                        0.141272        0.110486       0.161917  0.113575   \nFPR                        0.198208        0.177235       0.215770  0.169531   \nAccuracy                   0.827227        0.856862       0.806936  0.857489   \nF1                         0.816202        0.863924       0.785432  0.857287   \nSelection-Rate             0.493282        0.541080       0.478154  0.515705   \nPositive-Rate              1.104206        1.059242       1.134067  1.067977   \n\n                            SEX_dis  RAC1P_priv  RAC1P_dis  \nGeneral_Ensemble_Accuracy  0.798100    0.825000   0.831500  \nMean                       0.585400    0.539900   0.580300  \nStd                        0.027900    0.024800   0.028400  \nIQR                        0.035400    0.031400   0.036000  \nEntropy                    0.054700    0.040000   0.000000  \nJitter                     0.035500    0.025700   0.035600  \nPer_Sample_Accuracy        0.796200    0.823900   0.829100  \nLabel_Stability            0.950200    0.964000   0.950900  \nTPR                        0.827423    0.859287   0.857579  \nTNR                        0.777483    0.795947   0.812235  \nPPV                        0.722543    0.781077   0.770802  \nFNR                        0.172577    0.140713   0.142421  \nFPR                        0.222517    0.204053   0.187765  \nAccuracy                   0.798053    0.824998   0.831464  \nF1                         0.771435    0.818317   0.811878  \nSelection-Rate             0.471665    0.504577   0.471815  \nPositive-Rate              1.145154    1.100132   1.112581  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>SEX_RAC1P_priv</th>\n      <th>SEX_RAC1P_dis</th>\n      <th>SEX_priv</th>\n      <th>SEX_dis</th>\n      <th>RAC1P_priv</th>\n      <th>RAC1P_dis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>General_Ensemble_Accuracy</th>\n      <td>0.827200</td>\n      <td>0.856900</td>\n      <td>0.806900</td>\n      <td>0.857500</td>\n      <td>0.798100</td>\n      <td>0.825000</td>\n      <td>0.831500</td>\n    </tr>\n    <tr>\n      <th>Mean</th>\n      <td>0.553800</td>\n      <td>0.491800</td>\n      <td>0.580500</td>\n      <td>0.521100</td>\n      <td>0.585400</td>\n      <td>0.539900</td>\n      <td>0.580300</td>\n    </tr>\n    <tr>\n      <th>Std</th>\n      <td>0.026100</td>\n      <td>0.023500</td>\n      <td>0.031000</td>\n      <td>0.024200</td>\n      <td>0.027900</td>\n      <td>0.024800</td>\n      <td>0.028400</td>\n    </tr>\n    <tr>\n      <th>IQR</th>\n      <td>0.033000</td>\n      <td>0.029600</td>\n      <td>0.039500</td>\n      <td>0.030500</td>\n      <td>0.035400</td>\n      <td>0.031400</td>\n      <td>0.036000</td>\n    </tr>\n    <tr>\n      <th>Entropy</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.066300</td>\n      <td>0.000000</td>\n      <td>0.054700</td>\n      <td>0.040000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Jitter</th>\n      <td>0.029100</td>\n      <td>0.020000</td>\n      <td>0.042800</td>\n      <td>0.022500</td>\n      <td>0.035500</td>\n      <td>0.025700</td>\n      <td>0.035600</td>\n    </tr>\n    <tr>\n      <th>Per_Sample_Accuracy</th>\n      <td>0.825700</td>\n      <td>0.855500</td>\n      <td>0.803500</td>\n      <td>0.856200</td>\n      <td>0.796200</td>\n      <td>0.823900</td>\n      <td>0.829100</td>\n    </tr>\n    <tr>\n      <th>Label_Stability</th>\n      <td>0.959500</td>\n      <td>0.972700</td>\n      <td>0.940800</td>\n      <td>0.969100</td>\n      <td>0.950200</td>\n      <td>0.964000</td>\n      <td>0.950900</td>\n    </tr>\n    <tr>\n      <th>TPR</th>\n      <td>0.858728</td>\n      <td>0.889514</td>\n      <td>0.838083</td>\n      <td>0.886425</td>\n      <td>0.827423</td>\n      <td>0.859287</td>\n      <td>0.857579</td>\n    </tr>\n    <tr>\n      <th>TNR</th>\n      <td>0.801792</td>\n      <td>0.822765</td>\n      <td>0.784230</td>\n      <td>0.830469</td>\n      <td>0.777483</td>\n      <td>0.795947</td>\n      <td>0.812235</td>\n    </tr>\n    <tr>\n      <th>PPV</th>\n      <td>0.777688</td>\n      <td>0.839765</td>\n      <td>0.739006</td>\n      <td>0.830004</td>\n      <td>0.722543</td>\n      <td>0.781077</td>\n      <td>0.770802</td>\n    </tr>\n    <tr>\n      <th>FNR</th>\n      <td>0.141272</td>\n      <td>0.110486</td>\n      <td>0.161917</td>\n      <td>0.113575</td>\n      <td>0.172577</td>\n      <td>0.140713</td>\n      <td>0.142421</td>\n    </tr>\n    <tr>\n      <th>FPR</th>\n      <td>0.198208</td>\n      <td>0.177235</td>\n      <td>0.215770</td>\n      <td>0.169531</td>\n      <td>0.222517</td>\n      <td>0.204053</td>\n      <td>0.187765</td>\n    </tr>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.827227</td>\n      <td>0.856862</td>\n      <td>0.806936</td>\n      <td>0.857489</td>\n      <td>0.798053</td>\n      <td>0.824998</td>\n      <td>0.831464</td>\n    </tr>\n    <tr>\n      <th>F1</th>\n      <td>0.816202</td>\n      <td>0.863924</td>\n      <td>0.785432</td>\n      <td>0.857287</td>\n      <td>0.771435</td>\n      <td>0.818317</td>\n      <td>0.811878</td>\n    </tr>\n    <tr>\n      <th>Selection-Rate</th>\n      <td>0.493282</td>\n      <td>0.541080</td>\n      <td>0.478154</td>\n      <td>0.515705</td>\n      <td>0.471665</td>\n      <td>0.504577</td>\n      <td>0.471815</td>\n    </tr>\n    <tr>\n      <th>Positive-Rate</th>\n      <td>1.104206</td>\n      <td>1.059242</td>\n      <td>1.134067</td>\n      <td>1.067977</td>\n      <td>1.145154</td>\n      <td>1.100132</td>\n      <td>1.112581</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [13:08<26:17, 788.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "##############################  [Experiment 1] Analyze MLPClassifier_1L_100  ##############################\n",
      "Baseline X_train shape:  (80684, 16)\n",
      "Baseline X_test shape:  (20171, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:37:08 abstract_stability_analyzer.py INFO    : Start testing of classifier 1 / 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Protected groups splits:\n",
      "SEX_RAC1P_priv (6582, 16)\n",
      "SEX_RAC1P_dis (3543, 16)\n",
      "SEX_priv (9817, 16)\n",
      "SEX_dis (10354, 16)\n",
      "RAC1P_priv (13393, 16)\n",
      "RAC1P_dis (6778, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:39:54 abstract_stability_analyzer.py INFO    : Classifier 1 / 50 was tested\n",
      "2022-12-16 10:39:54 abstract_stability_analyzer.py INFO    : Start testing of classifier 2 / 50\n",
      "2022-12-16 10:42:44 abstract_stability_analyzer.py INFO    : Classifier 2 / 50 was tested\n",
      "2022-12-16 10:42:44 abstract_stability_analyzer.py INFO    : Start testing of classifier 3 / 50\n",
      "2022-12-16 10:45:36 abstract_stability_analyzer.py INFO    : Classifier 3 / 50 was tested\n",
      "2022-12-16 10:45:36 abstract_stability_analyzer.py INFO    : Start testing of classifier 4 / 50\n",
      "2022-12-16 10:48:28 abstract_stability_analyzer.py INFO    : Classifier 4 / 50 was tested\n",
      "2022-12-16 10:48:28 abstract_stability_analyzer.py INFO    : Start testing of classifier 5 / 50\n",
      "2022-12-16 10:50:40 abstract_stability_analyzer.py INFO    : Classifier 5 / 50 was tested\n",
      "2022-12-16 10:50:40 abstract_stability_analyzer.py INFO    : Start testing of classifier 6 / 50\n",
      "2022-12-16 10:51:12 abstract_stability_analyzer.py INFO    : Classifier 6 / 50 was tested\n",
      "2022-12-16 10:51:12 abstract_stability_analyzer.py INFO    : Start testing of classifier 7 / 50\n",
      "2022-12-16 10:51:13 abstract_stability_analyzer.py INFO    : Classifier 7 / 50 was tested\n",
      "2022-12-16 10:51:13 abstract_stability_analyzer.py INFO    : Start testing of classifier 8 / 50\n",
      " 33%|███▎      | 1/3 [27:14<54:29, 1634.67s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# TOD: add dataset as a parameter\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 9\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(exp_num, model_seed)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      6\u001B[0m     base_model \u001B[38;5;241m=\u001B[39m create_tuned_base_model(config\u001B[38;5;241m.\u001B[39mMODELS_CONFIG[model_idx][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      7\u001B[0m                                          config\u001B[38;5;241m.\u001B[39mMODELS_CONFIG[model_idx][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      8\u001B[0m                                          models_tuned_params_df)\n\u001B[0;32m----> 9\u001B[0m     results_df \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_ESTIMATORS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPROTECTED_GROUPS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPRIV_VALUES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mmodel_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDATASET_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mbase_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMODELS_CONFIG\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mexp_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_num\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m[Experiment \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexp_num\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] Metrics confusion matrix:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m     display(results_df)\n",
      "Cell \u001B[0;32mIn[7], line 23\u001B[0m, in \u001B[0;36mget_model_metrics\u001B[0;34m(base_model, n_estimators, dataset, protected_groups, priv_values, model_seed, dataset_name, base_model_name, exp_num)\u001B[0m\n\u001B[1;32m     16\u001B[0m stability_fairness_analyzer \u001B[38;5;241m=\u001B[39m StabilityFairnessAnalyzer(ModelSetting\u001B[38;5;241m.\u001B[39mBATCH, n_estimators, base_model, base_model_name,\n\u001B[1;32m     17\u001B[0m                                                         base_pipeline\u001B[38;5;241m.\u001B[39mX_train_val, base_pipeline\u001B[38;5;241m.\u001B[39my_train_val,\n\u001B[1;32m     18\u001B[0m                                                         base_pipeline\u001B[38;5;241m.\u001B[39mX_test, base_pipeline\u001B[38;5;241m.\u001B[39my_test,\n\u001B[1;32m     19\u001B[0m                                                         base_pipeline\u001B[38;5;241m.\u001B[39mprotected_groups, base_pipeline\u001B[38;5;241m.\u001B[39mpriv_values, base_pipeline\u001B[38;5;241m.\u001B[39mtest_groups,\n\u001B[1;32m     20\u001B[0m                                                         base_pipeline\u001B[38;5;241m.\u001B[39mtarget, dataset_name)\n\u001B[1;32m     22\u001B[0m save_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m y_preds, variance_metrics_df \u001B[38;5;241m=\u001B[39m \u001B[43mstability_fairness_analyzer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                                                           \u001B[49m\u001B[43mresult_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m                                                                           \u001B[49m\u001B[43msave_dir_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m                                                                           \u001B[49m\u001B[43mmake_plots\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m bias_analyzer \u001B[38;5;241m=\u001B[39m BiasAnalyzer(base_pipeline\u001B[38;5;241m.\u001B[39mX_test, base_pipeline\u001B[38;5;241m.\u001B[39my_test,\n\u001B[1;32m     29\u001B[0m                              base_pipeline\u001B[38;5;241m.\u001B[39mprotected_groups, base_pipeline\u001B[38;5;241m.\u001B[39mpriv_values,\n\u001B[1;32m     30\u001B[0m                              base_pipeline\u001B[38;5;241m.\u001B[39mtest_groups)\n\u001B[1;32m     31\u001B[0m dtc_res \u001B[38;5;241m=\u001B[39m bias_analyzer\u001B[38;5;241m.\u001B[39mcompute_subgroups_metrics(y_preds,\n\u001B[1;32m     32\u001B[0m                                                   save_results\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     33\u001B[0m                                                   result_filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     34\u001B[0m                                                   save_dir_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/UCU/4course_2term/Bachelor_Thesis/Code/fairness-variance/utils/analyzers/stability_fairness_analyzer.py:41\u001B[0m, in \u001B[0;36mStabilityFairnessAnalyzer.compute_metrics\u001B[0;34m(self, save_results, result_filename, save_dir_path, make_plots)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_metrics\u001B[39m(\u001B[38;5;28mself\u001B[39m, save_results, result_filename, save_dir_path, make_plots\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,):\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03m    Measure metrics for the base model. Display stability plots for analysis if needed. Save results to a .pkl file\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m    :param make_plots: bool, if display plots for analysis\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m     y_preds, y_test_true \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__stability_analyzer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmake_plots\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstability_metrics_dct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__stability_analyzer\u001B[38;5;241m.\u001B[39mget_metrics_dict()\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m# Count and display fairness metrics\u001B[39;00m\n",
      "File \u001B[0;32m~/UCU/4course_2term/Bachelor_Thesis/Code/fairness-variance/utils/analyzers/abstract_stability_analyzer.py:74\u001B[0m, in \u001B[0;36mAbstractStabilityAnalyzer.compute_metrics\u001B[0;34m(self, make_plots, save_results)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;66;03m# Quantify uncertainty for the base model\u001B[39;00m\n\u001B[1;32m     73\u001B[0m boostrap_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbootstrap_fraction \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mUQ_by_boostrap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboostrap_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_replacement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# Count metrics based on prediction proba results\u001B[39;00m\n\u001B[1;32m     77\u001B[0m y_preds, uq_labels, prediction_stats \u001B[38;5;241m=\u001B[39m count_prediction_stats(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_test\u001B[38;5;241m.\u001B[39mvalues, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels_predictions)\n",
      "File \u001B[0;32m~/UCU/4course_2term/Bachelor_Thesis/Code/fairness-variance/utils/analyzers/abstract_stability_analyzer.py:118\u001B[0m, in \u001B[0;36mAbstractStabilityAnalyzer.UQ_by_boostrap\u001B[0;34m(self, boostrap_size, with_replacement)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStart testing of classifier \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m / \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    117\u001B[0m classifier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels_lst[idx]\n\u001B[0;32m--> 118\u001B[0m X_sample, y_sample \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_bootstrap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mboostrap_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_replacement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m classifier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_model(classifier, X_sample, y_sample)\n\u001B[1;32m    120\u001B[0m models_predictions[idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_predict_proba(classifier, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_test)\n",
      "File \u001B[0;32m~/UCU/4course_2term/Bachelor_Thesis/Code/fairness-variance/utils/stability_utils.py:144\u001B[0m, in \u001B[0;36mgenerate_bootstrap\u001B[0;34m(features, labels, boostrap_size, with_replacement)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_bootstrap\u001B[39m(features, labels, boostrap_size, with_replacement\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    143\u001B[0m     bootstrap_index \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(features\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], size\u001B[38;5;241m=\u001B[39mboostrap_size, replace\u001B[38;5;241m=\u001B[39mwith_replacement)\n\u001B[0;32m--> 144\u001B[0m     bootstrap_features \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbootstrap_index\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m    145\u001B[0m     bootstrap_labels \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(labels)\u001B[38;5;241m.\u001B[39miloc[bootstrap_index]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(bootstrap_features) \u001B[38;5;241m==\u001B[39m boostrap_size:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# TOD: add dataset as a parameter\n",
    "run_experiment(exp_num=1, model_seed=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run_experiment(exp_num=2, model_seed=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}